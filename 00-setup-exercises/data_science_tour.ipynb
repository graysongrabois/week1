{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì A Tour of Data Science: Why It Matters\n",
    "\n",
    "## Student Performance Analysis\n",
    "\n",
    "Welcome to this hands-on tour of data science! In this notebook, we'll explore a real dataset of student performance and demonstrate the core skills that make data science such a valuable and in-demand discipline.\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Loading & Exploring Data** - First contact with your data\n",
    "2. **Data Cleaning** - Handling real-world messiness\n",
    "3. **Filtering & Subsetting** - Finding needles in haystacks\n",
    "4. **Descriptive Statistics** - Summarizing thousands of records in seconds\n",
    "5. **Data Visualization** - A picture is worth a thousand data points\n",
    "6. **Correlation Analysis** - Discovering hidden relationships\n",
    "7. **Group-by Operations** - Powerful aggregations\n",
    "8. **Feature Engineering** - Creating new insights from existing data\n",
    "9. **Predictive Insights** - From data to decisions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Part 1: Setting Up Our Tools\n",
    "\n",
    "Every data scientist starts with their toolkit. Think of these libraries as power tools that turn hours of manual work into seconds of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Statistical tools\n",
    "from scipy import stats\n",
    "\n",
    "# Configure visualization defaults\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")\n",
    "print(f\"üìä Pandas version: {pd.__version__}\")\n",
    "print(f\"üî¢ NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÇ Part 2: Loading and First Look at the Data\n",
    "\n",
    "### Why This Matters\n",
    "Before making any decisions, you need to understand what you're working with. Imagine making business decisions about 14,000 students without ever looking at the data ‚Äî that's how many organizations operated before data science became mainstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('student_performance.csv')\n",
    "\n",
    "# First glimpse - how big is our data?\n",
    "print(\"=\"*60)\n",
    "print(\"üìä DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüî¢ Total Records: {len(df):,}\")\n",
    "print(f\"üìã Total Features: {len(df.columns)}\")\n",
    "print(f\"üíæ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the first few rows\n",
    "print(\"\\nüìã First 5 Records:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What columns do we have?\n",
    "print(\"\\nüìë Column Names and Data Types:\")\n",
    "print(\"-\"*40)\n",
    "for col in df.columns:\n",
    "    print(f\"  ‚Ä¢ {col}: {df[col].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistical summary\n",
    "print(\"\\nüìà Statistical Summary:\")\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Insight Box\n",
    "\n",
    "In just a few lines of code, we learned:\n",
    "- We have **14,000+ student records**\n",
    "- Students study between **5-40 hours** per week\n",
    "- Attendance ranges from **60-100%**\n",
    "- Exam scores span the full **40-100** range\n",
    "- Ages range from **18-29** years\n",
    "\n",
    "**Without data science**, discovering this would require manually reviewing thousands of records!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Part 3: Data Cleaning and Understanding\n",
    "\n",
    "### Why This Matters\n",
    "Real-world data is messy. Data scientists spend **60-80% of their time** cleaning and preparing data. Bad data leads to bad decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"üîç Missing Values Check:\")\n",
    "print(\"-\"*40)\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"‚úÖ No missing values found! This data is clean.\")\n",
    "else:\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nüîÑ Duplicate Rows: {duplicates:,}\")\n",
    "print(f\"üìä Unique Records: {len(df) - duplicates:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's decode the categorical variables for better understanding\n",
    "# Create a copy with meaningful labels\n",
    "df_labeled = df.copy()\n",
    "\n",
    "# Decode FinalGrade (0=A, 1=B, 2=C, 3=D/F based on typical grading)\n",
    "grade_map = {0: 'A (Excellent)', 1: 'B (Good)', 2: 'C (Average)', 3: 'D/F (Poor)'}\n",
    "df_labeled['GradeLabel'] = df['FinalGrade'].map(grade_map)\n",
    "\n",
    "# Decode Gender\n",
    "df_labeled['GenderLabel'] = df['Gender'].map({0: 'Female', 1: 'Male'})\n",
    "\n",
    "# Decode Motivation\n",
    "motivation_map = {0: 'Low', 1: 'Medium', 2: 'High'}\n",
    "df_labeled['MotivationLabel'] = df['Motivation'].map(motivation_map)\n",
    "\n",
    "# Decode StressLevel\n",
    "stress_map = {0: 'Low', 1: 'Medium', 2: 'High'}\n",
    "df_labeled['StressLabel'] = df['StressLevel'].map(stress_map)\n",
    "\n",
    "# Decode LearningStyle\n",
    "learning_map = {0: 'Visual', 1: 'Auditory', 2: 'Reading/Writing', 3: 'Kinesthetic'}\n",
    "df_labeled['LearningStyleLabel'] = df['LearningStyle'].map(learning_map)\n",
    "\n",
    "print(\"‚úÖ Created labeled version of dataset for easier interpretation!\")\n",
    "print(\"\\nüìã Sample with labels:\")\n",
    "df_labeled[['StudyHours', 'ExamScore', 'GradeLabel', 'GenderLabel', 'MotivationLabel']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Part 4: Filtering and Subsetting Data\n",
    "\n",
    "### Why This Matters\n",
    "Organizations need to answer specific questions:\n",
    "- *\"Which students are at risk of failing?\"*\n",
    "- *\"Who are our top performers?\"*\n",
    "- *\"What characterizes successful students?\"*\n",
    "\n",
    "Filtering lets us zoom in on exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Find High Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: Students with A grades (FinalGrade == 0)\n",
    "top_students = df_labeled[df_labeled['FinalGrade'] == 0]\n",
    "\n",
    "print(\"üèÜ TOP PERFORMERS (A Grade Students)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Count: {len(top_students):,} students ({len(top_students)/len(df)*100:.1f}% of total)\")\n",
    "print(f\"\\nAverage Study Hours: {top_students['StudyHours'].mean():.1f}\")\n",
    "print(f\"Average Attendance: {top_students['Attendance'].mean():.1f}%\")\n",
    "print(f\"Average Exam Score: {top_students['ExamScore'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Find At-Risk Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter: Students with D/F grades (FinalGrade == 3)\n",
    "at_risk = df_labeled[df_labeled['FinalGrade'] == 3]\n",
    "\n",
    "print(\"‚ö†Ô∏è AT-RISK STUDENTS (D/F Grade)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Count: {len(at_risk):,} students ({len(at_risk)/len(df)*100:.1f}% of total)\")\n",
    "print(f\"\\nAverage Study Hours: {at_risk['StudyHours'].mean():.1f}\")\n",
    "print(f\"Average Attendance: {at_risk['Attendance'].mean():.1f}%\")\n",
    "print(f\"Average Exam Score: {at_risk['ExamScore'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3: Complex Filtering with Multiple Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find students who study a lot (>25 hours) but still have poor grades\n",
    "# These are interesting cases - what's going wrong?\n",
    "\n",
    "puzzling_cases = df_labeled[\n",
    "    (df_labeled['StudyHours'] >= 25) & \n",
    "    (df_labeled['FinalGrade'] == 3)\n",
    "]\n",
    "\n",
    "print(\"ü§î PUZZLING CASES: High Study Hours but Poor Grades\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Found {len(puzzling_cases):,} students who study 25+ hours but still have D/F grades\")\n",
    "print(f\"\\nTheir characteristics:\")\n",
    "print(f\"  ‚Ä¢ Average Attendance: {puzzling_cases['Attendance'].mean():.1f}%\")\n",
    "print(f\"  ‚Ä¢ Average Exam Score: {puzzling_cases['ExamScore'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ High Stress Level: {(puzzling_cases['StressLevel'] == 2).mean()*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Participates in Discussions: {puzzling_cases['Discussions'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the \"efficient\" students - low study hours but great grades\n",
    "efficient_students = df_labeled[\n",
    "    (df_labeled['StudyHours'] <= 15) & \n",
    "    (df_labeled['FinalGrade'] == 0)\n",
    "]\n",
    "\n",
    "print(\"‚ö° EFFICIENT LEARNERS: Low Study Hours, Great Grades\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Found {len(efficient_students):,} students who study ‚â§15 hours and have A grades\")\n",
    "print(f\"\\nTheir secret sauce:\")\n",
    "print(f\"  ‚Ä¢ Average Attendance: {efficient_students['Attendance'].mean():.1f}%\")\n",
    "print(f\"  ‚Ä¢ Average Exam Score: {efficient_students['ExamScore'].mean():.1f}\")\n",
    "print(f\"  ‚Ä¢ Participates in Discussions: {efficient_students['Discussions'].mean()*100:.1f}%\")\n",
    "print(f\"  ‚Ä¢ Assignment Completion: {efficient_students['AssignmentCompletion'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.4: Using Query Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas also supports SQL-like query syntax\n",
    "# Find young students (under 21) with high motivation who use educational technology\n",
    "\n",
    "young_motivated = df.query('Age < 21 and Motivation == 2 and EduTech == 1')\n",
    "\n",
    "print(\"üéØ YOUNG, MOTIVATED, TECH-SAVVY STUDENTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Count: {len(young_motivated):,}\")\n",
    "print(f\"Average Final Grade: {young_motivated['FinalGrade'].mean():.2f} (lower is better, 0=A)\")\n",
    "print(f\"Average Exam Score: {young_motivated['ExamScore'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Part 5: Data Visualization\n",
    "\n",
    "### Why This Matters\n",
    "Humans are visual creatures. A well-designed chart can reveal patterns that would take hours to find in raw numbers. As the saying goes:\n",
    "\n",
    "> *\"A picture is worth a thousand data points.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Distribution of Final Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart\n",
    "grade_counts = df_labeled['GradeLabel'].value_counts()\n",
    "colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']\n",
    "grade_order = ['A (Excellent)', 'B (Good)', 'C (Average)', 'D/F (Poor)']\n",
    "grade_counts = grade_counts.reindex(grade_order)\n",
    "\n",
    "axes[0].bar(grade_counts.index, grade_counts.values, color=colors, edgecolor='black', linewidth=1.2)\n",
    "axes[0].set_title('Distribution of Final Grades', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Grade')\n",
    "axes[0].set_ylabel('Number of Students')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(grade_counts.values):\n",
    "    axes[0].text(i, v + 100, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(grade_counts.values, labels=grade_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors, explode=[0.05, 0, 0, 0.05], shadow=True, startangle=90)\n",
    "axes[1].set_title('Grade Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('grade_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Insight: The grade distribution shows how students are performing overall.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.2: Study Hours vs. Exam Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with regression line\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "# Create scatter plot colored by grade\n",
    "scatter = ax.scatter(df['StudyHours'], df['ExamScore'], \n",
    "                     c=df['FinalGrade'], cmap='RdYlGn_r', \n",
    "                     alpha=0.5, s=30, edgecolors='white', linewidth=0.5)\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(df['StudyHours'], df['ExamScore'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax.plot(df['StudyHours'].sort_values(), p(df['StudyHours'].sort_values()), \n",
    "        'r--', linewidth=2, label=f'Trend Line')\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = df['StudyHours'].corr(df['ExamScore'])\n",
    "\n",
    "ax.set_xlabel('Study Hours per Week', fontsize=12)\n",
    "ax.set_ylabel('Exam Score', fontsize=12)\n",
    "ax.set_title(f'Study Hours vs. Exam Score\\n(Correlation: {correlation:.3f})', \n",
    "             fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Final Grade (0=A, 3=D/F)', fontsize=10)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.savefig('study_vs_exam.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üí° Insight: Correlation between study hours and exam scores is {correlation:.3f}\")\n",
    "print(\"   This suggests study hours alone don't strongly predict exam performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.3: Box Plots - Comparing Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare exam scores across different grades\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Exam scores by grade\n",
    "grade_order = ['A (Excellent)', 'B (Good)', 'C (Average)', 'D/F (Poor)']\n",
    "sns.boxplot(data=df_labeled, x='GradeLabel', y='ExamScore', order=grade_order,\n",
    "            palette=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'], ax=axes[0])\n",
    "axes[0].set_title('Exam Scores by Final Grade', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Final Grade')\n",
    "axes[0].set_ylabel('Exam Score')\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Study hours by grade\n",
    "sns.boxplot(data=df_labeled, x='GradeLabel', y='StudyHours', order=grade_order,\n",
    "            palette=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'], ax=axes[1])\n",
    "axes[1].set_title('Study Hours by Final Grade', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Final Grade')\n",
    "axes[1].set_ylabel('Study Hours per Week')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('boxplots_by_grade.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Insight: Box plots reveal the spread and outliers in each grade group.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.4: Histograms - Understanding Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple histograms for key variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Study Hours Distribution\n",
    "axes[0, 0].hist(df['StudyHours'], bins=20, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(df['StudyHours'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {df['StudyHours'].mean():.1f}\")\n",
    "axes[0, 0].set_title('Distribution of Study Hours', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Study Hours per Week')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Attendance Distribution\n",
    "axes[0, 1].hist(df['Attendance'], bins=20, color='#2ecc71', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(df['Attendance'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {df['Attendance'].mean():.1f}%\")\n",
    "axes[0, 1].set_title('Distribution of Attendance', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Attendance (%)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Exam Score Distribution\n",
    "axes[1, 0].hist(df['ExamScore'], bins=20, color='#9b59b6', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(df['ExamScore'].mean(), color='red', linestyle='--', linewidth=2, label=f\"Mean: {df['ExamScore'].mean():.1f}\")\n",
    "axes[1, 0].set_title('Distribution of Exam Scores', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Exam Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Age Distribution\n",
    "axes[1, 1].hist(df['Age'], bins=12, color='#e74c3c', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(df['Age'].mean(), color='blue', linestyle='--', linewidth=2, label=f\"Mean: {df['Age'].mean():.1f}\")\n",
    "axes[1, 1].set_title('Distribution of Student Age', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Age (years)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('distributions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.5: Heatmap - The Power of Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numeric columns\n",
    "numeric_cols = ['StudyHours', 'Attendance', 'Age', 'OnlineCourses', \n",
    "                'AssignmentCompletion', 'ExamScore', 'FinalGrade', \n",
    "                'Motivation', 'StressLevel']\n",
    "\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='RdBu_r', center=0, square=True, linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.8, 'label': 'Correlation Coefficient'},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Heatmap: What Factors Are Related?', \n",
    "             fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Key Correlations with Final Grade (negative = better grade):\")\n",
    "grade_corr = correlation_matrix['FinalGrade'].drop('FinalGrade').sort_values()\n",
    "for feature, corr in grade_corr.items():\n",
    "    direction = \"‚¨áÔ∏è Lower grades (better)\" if corr < 0 else \"‚¨ÜÔ∏è Higher grades (worse)\"\n",
    "    print(f\"   ‚Ä¢ {feature}: {corr:.3f} ‚Üí {direction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîó Part 6: Group-By Operations\n",
    "\n",
    "### Why This Matters\n",
    "Group-by operations are the bread and butter of data analysis. They let you answer questions like:\n",
    "- *\"What's the average exam score for each learning style?\"*\n",
    "- *\"How does stress level affect performance?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by Learning Style\n",
    "print(\"üìö PERFORMANCE BY LEARNING STYLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "learning_stats = df_labeled.groupby('LearningStyleLabel').agg({\n",
    "    'ExamScore': ['mean', 'std', 'count'],\n",
    "    'FinalGrade': 'mean',\n",
    "    'StudyHours': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "learning_stats.columns = ['Avg Exam Score', 'Std Dev', 'Count', 'Avg Grade (0=A)', 'Avg Study Hours']\n",
    "print(learning_stats.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by Stress Level\n",
    "print(\"\\nüò∞ PERFORMANCE BY STRESS LEVEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "stress_stats = df_labeled.groupby('StressLabel').agg({\n",
    "    'ExamScore': 'mean',\n",
    "    'FinalGrade': 'mean',\n",
    "    'AssignmentCompletion': 'mean',\n",
    "    'StudyHours': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "stress_stats.columns = ['Avg Exam Score', 'Avg Grade (0=A)', 'Assignment Completion %', 'Avg Study Hours']\n",
    "stress_order = ['Low', 'Medium', 'High']\n",
    "print(stress_stats.reindex(stress_order).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stress level impact\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Exam scores by stress level\n",
    "stress_order = ['Low', 'Medium', 'High']\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "sns.barplot(data=df_labeled, x='StressLabel', y='ExamScore', order=stress_order,\n",
    "            palette=colors, ax=axes[0], errorbar='sd')\n",
    "axes[0].set_title('Exam Score by Stress Level', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Stress Level')\n",
    "axes[0].set_ylabel('Average Exam Score')\n",
    "\n",
    "# Grade distribution by stress level\n",
    "stress_grade = df_labeled.groupby(['StressLabel', 'GradeLabel']).size().unstack(fill_value=0)\n",
    "stress_grade = stress_grade.reindex(stress_order)\n",
    "grade_order = ['A (Excellent)', 'B (Good)', 'C (Average)', 'D/F (Poor)']\n",
    "stress_grade = stress_grade[grade_order]\n",
    "\n",
    "stress_grade.plot(kind='bar', stacked=True, ax=axes[1], \n",
    "                  color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'])\n",
    "axes[1].set_title('Grade Distribution by Stress Level', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Stress Level')\n",
    "axes[1].set_ylabel('Number of Students')\n",
    "axes[1].legend(title='Grade', bbox_to_anchor=(1.02, 1))\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('stress_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Part 7: Feature Engineering\n",
    "\n",
    "### Why This Matters\n",
    "Feature engineering is the art of creating new variables from existing data. It's often what separates good analysis from great analysis. We can combine multiple factors to create more meaningful metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "# 1. Study Efficiency: Exam Score per Study Hour\n",
    "df_enhanced['StudyEfficiency'] = df_enhanced['ExamScore'] / df_enhanced['StudyHours']\n",
    "\n",
    "# 2. Engagement Score: Combination of attendance, discussions, and assignment completion\n",
    "df_enhanced['EngagementScore'] = (\n",
    "    df_enhanced['Attendance'] * 0.4 + \n",
    "    df_enhanced['Discussions'] * 20 + \n",
    "    df_enhanced['AssignmentCompletion'] * 0.4\n",
    ")\n",
    "\n",
    "# 3. Resource Utilization: Internet + EduTech + OnlineCourses\n",
    "df_enhanced['ResourceUtilization'] = (\n",
    "    df_enhanced['Internet'] * 2 + \n",
    "    df_enhanced['EduTech'] * 2 + \n",
    "    df_enhanced['OnlineCourses'] / 2\n",
    ")\n",
    "\n",
    "# 4. Age Group\n",
    "df_enhanced['AgeGroup'] = pd.cut(df_enhanced['Age'], \n",
    "                                  bins=[17, 20, 24, 30], \n",
    "                                  labels=['18-20', '21-24', '25+'])\n",
    "\n",
    "# 5. Performance Category (based on exam score)\n",
    "df_enhanced['PerformanceCategory'] = pd.cut(df_enhanced['ExamScore'],\n",
    "                                             bins=[0, 50, 70, 85, 100],\n",
    "                                             labels=['Struggling', 'Below Average', 'Good', 'Excellent'])\n",
    "\n",
    "print(\"‚úÖ Created 5 new engineered features!\")\n",
    "print(\"\\nüìã Sample of new features:\")\n",
    "df_enhanced[['StudyHours', 'ExamScore', 'StudyEfficiency', 'EngagementScore', \n",
    "             'ResourceUtilization', 'AgeGroup', 'PerformanceCategory']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the new features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Study Efficiency by Grade\n",
    "grade_order = [0, 1, 2, 3]\n",
    "grade_labels = ['A', 'B', 'C', 'D/F']\n",
    "efficiency_by_grade = df_enhanced.groupby('FinalGrade')['StudyEfficiency'].mean()\n",
    "\n",
    "axes[0, 0].bar(grade_labels, efficiency_by_grade.values, color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'])\n",
    "axes[0, 0].set_title('Study Efficiency by Grade', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Final Grade')\n",
    "axes[0, 0].set_ylabel('Exam Score per Study Hour')\n",
    "\n",
    "# Engagement Score Distribution\n",
    "axes[0, 1].hist(df_enhanced['EngagementScore'], bins=30, color='#9b59b6', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(df_enhanced['EngagementScore'].mean(), color='red', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_title('Distribution of Engagement Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Engagement Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Performance by Age Group\n",
    "age_performance = df_enhanced.groupby('AgeGroup')['ExamScore'].mean()\n",
    "axes[1, 0].bar(age_performance.index.astype(str), age_performance.values, color='#3498db', edgecolor='black')\n",
    "axes[1, 0].set_title('Average Exam Score by Age Group', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Age Group')\n",
    "axes[1, 0].set_ylabel('Average Exam Score')\n",
    "\n",
    "# Engagement vs Exam Score\n",
    "axes[1, 1].scatter(df_enhanced['EngagementScore'], df_enhanced['ExamScore'], \n",
    "                   alpha=0.3, c=df_enhanced['FinalGrade'], cmap='RdYlGn_r')\n",
    "axes[1, 1].set_title('Engagement Score vs Exam Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Engagement Score')\n",
    "axes[1, 1].set_ylabel('Exam Score')\n",
    "\n",
    "# Add correlation\n",
    "corr = df_enhanced['EngagementScore'].corr(df_enhanced['ExamScore'])\n",
    "axes[1, 1].annotate(f'Correlation: {corr:.3f}', xy=(0.05, 0.95), xycoords='axes fraction',\n",
    "                    fontsize=12, fontweight='bold', bbox=dict(boxstyle='round', facecolor='white'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_engineering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° Insight: Our engineered 'Engagement Score' shows stronger correlation with exam scores!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Part 8: Predictive Insights\n",
    "\n",
    "### Why This Matters\n",
    "The ultimate goal of data science is to move from *descriptive* (\"what happened?\") to *predictive* (\"what will happen?\") to *prescriptive* (\"what should we do?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the key predictors of success?\n",
    "print(\"üéØ KEY PREDICTORS OF STUDENT SUCCESS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate correlations with FinalGrade (remember: lower grade number = better)\n",
    "predictors = ['StudyHours', 'Attendance', 'Motivation', 'AssignmentCompletion', \n",
    "              'ExamScore', 'Discussions', 'EduTech', 'StressLevel', 'OnlineCourses']\n",
    "\n",
    "correlations = df[predictors + ['FinalGrade']].corr()['FinalGrade'].drop('FinalGrade')\n",
    "correlations_sorted = correlations.sort_values()\n",
    "\n",
    "print(\"\\nüìä Correlation with Final Grade (negative = helps, positive = hurts):\")\n",
    "print(\"-\"*60)\n",
    "for feature, corr in correlations_sorted.items():\n",
    "    bar_length = int(abs(corr) * 40)\n",
    "    if corr < 0:\n",
    "        bar = 'üü¢' * bar_length\n",
    "        effect = \"HELPS\"\n",
    "    else:\n",
    "        bar = 'üî¥' * bar_length\n",
    "        effect = \"HURTS\"\n",
    "    print(f\"{feature:25} {corr:+.3f} {bar} ({effect})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"Success Profile\" - what do top students look like?\n",
    "print(\"\\nüèÜ SUCCESS PROFILE: What Makes an A Student?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "a_students = df[df['FinalGrade'] == 0]\n",
    "all_students = df\n",
    "\n",
    "comparison_features = ['StudyHours', 'Attendance', 'AssignmentCompletion', \n",
    "                       'ExamScore', 'Discussions', 'Motivation']\n",
    "\n",
    "print(f\"\\n{'Feature':<25} {'A Students':>15} {'All Students':>15} {'Difference':>15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for feature in comparison_features:\n",
    "    a_mean = a_students[feature].mean()\n",
    "    all_mean = all_students[feature].mean()\n",
    "    diff = a_mean - all_mean\n",
    "    diff_pct = (diff / all_mean) * 100 if all_mean != 0 else 0\n",
    "    \n",
    "    arrow = \"‚Üë\" if diff > 0 else \"‚Üì\"\n",
    "    print(f\"{feature:<25} {a_mean:>15.1f} {all_mean:>15.1f} {arrow} {abs(diff_pct):>12.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"At-Risk Detector\"\n",
    "def identify_at_risk(row):\n",
    "    \"\"\"Identify students at risk of poor performance based on key indicators.\"\"\"\n",
    "    risk_score = 0\n",
    "    risk_factors = []\n",
    "    \n",
    "    if row['Attendance'] < 75:\n",
    "        risk_score += 2\n",
    "        risk_factors.append('Low Attendance')\n",
    "    \n",
    "    if row['AssignmentCompletion'] < 60:\n",
    "        risk_score += 2\n",
    "        risk_factors.append('Low Assignment Completion')\n",
    "    \n",
    "    if row['StudyHours'] < 10:\n",
    "        risk_score += 1\n",
    "        risk_factors.append('Very Low Study Hours')\n",
    "    \n",
    "    if row['Motivation'] == 0:\n",
    "        risk_score += 1\n",
    "        risk_factors.append('Low Motivation')\n",
    "    \n",
    "    if row['ExamScore'] < 50:\n",
    "        risk_score += 2\n",
    "        risk_factors.append('Low Exam Scores')\n",
    "    \n",
    "    if row['StressLevel'] == 2:\n",
    "        risk_score += 1\n",
    "        risk_factors.append('High Stress')\n",
    "    \n",
    "    return pd.Series({'RiskScore': risk_score, 'RiskFactors': ', '.join(risk_factors) if risk_factors else 'None'})\n",
    "\n",
    "# Apply the risk detector\n",
    "risk_analysis = df.apply(identify_at_risk, axis=1)\n",
    "df_with_risk = pd.concat([df, risk_analysis], axis=1)\n",
    "\n",
    "# Analyze risk levels\n",
    "print(\"‚ö†Ô∏è AT-RISK STUDENT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "risk_levels = pd.cut(df_with_risk['RiskScore'], \n",
    "                     bins=[-1, 1, 3, 5, 10],\n",
    "                     labels=['Low Risk', 'Moderate Risk', 'High Risk', 'Critical Risk'])\n",
    "\n",
    "print(\"\\nüìä Risk Distribution:\")\n",
    "for level in ['Low Risk', 'Moderate Risk', 'High Risk', 'Critical Risk']:\n",
    "    count = (risk_levels == level).sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   {level}: {count:,} students ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate our risk detector - does it actually predict poor grades?\n",
    "df_with_risk['RiskLevel'] = pd.cut(df_with_risk['RiskScore'], \n",
    "                                    bins=[-1, 1, 3, 5, 10],\n",
    "                                    labels=['Low Risk', 'Moderate Risk', 'High Risk', 'Critical Risk'])\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Grade distribution by risk level\n",
    "risk_grade = pd.crosstab(df_with_risk['RiskLevel'], df_with_risk['FinalGrade'], normalize='index') * 100\n",
    "risk_grade.columns = ['A', 'B', 'C', 'D/F']\n",
    "\n",
    "risk_grade.plot(kind='bar', stacked=True, ax=axes[0],\n",
    "                color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'])\n",
    "axes[0].set_title('Grade Distribution by Risk Level', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Risk Level')\n",
    "axes[0].set_ylabel('Percentage')\n",
    "axes[0].legend(title='Grade', bbox_to_anchor=(1.02, 1))\n",
    "axes[0].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# D/F rate by risk level\n",
    "df_rate = df_with_risk.groupby('RiskLevel')['FinalGrade'].apply(lambda x: (x == 3).mean() * 100)\n",
    "colors = ['#2ecc71', '#f39c12', '#e67e22', '#e74c3c']\n",
    "bars = axes[1].bar(df_rate.index, df_rate.values, color=colors, edgecolor='black')\n",
    "axes[1].set_title('D/F Rate by Risk Level', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Risk Level')\n",
    "axes[1].set_ylabel('% with D/F Grade')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, df_rate.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                 f'{val:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('risk_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Insight: Our risk detector successfully identifies students likely to struggle!\")\n",
    "print(\"   Critical Risk students have a significantly higher D/F rate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Part 9: Advanced Visualization - Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive dashboard-style visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Define grid\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Top performer characteristics (radar-like bar chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "top_vs_bottom = pd.DataFrame({\n",
    "    'Feature': ['Study\\nHours', 'Attendance', 'Motivation', 'Discussions', 'Assignment\\nCompletion'],\n",
    "    'A Students': [\n",
    "        df[df['FinalGrade']==0]['StudyHours'].mean() / df['StudyHours'].max() * 100,\n",
    "        df[df['FinalGrade']==0]['Attendance'].mean(),\n",
    "        df[df['FinalGrade']==0]['Motivation'].mean() / 2 * 100,\n",
    "        df[df['FinalGrade']==0]['Discussions'].mean() * 100,\n",
    "        df[df['FinalGrade']==0]['AssignmentCompletion'].mean()\n",
    "    ],\n",
    "    'D/F Students': [\n",
    "        df[df['FinalGrade']==3]['StudyHours'].mean() / df['StudyHours'].max() * 100,\n",
    "        df[df['FinalGrade']==3]['Attendance'].mean(),\n",
    "        df[df['FinalGrade']==3]['Motivation'].mean() / 2 * 100,\n",
    "        df[df['FinalGrade']==3]['Discussions'].mean() * 100,\n",
    "        df[df['FinalGrade']==3]['AssignmentCompletion'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "x = np.arange(len(top_vs_bottom['Feature']))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, top_vs_bottom['A Students'], width, label='A Students', color='#2ecc71')\n",
    "ax1.bar(x + width/2, top_vs_bottom['D/F Students'], width, label='D/F Students', color='#e74c3c')\n",
    "ax1.set_ylabel('Normalized Score')\n",
    "ax1.set_title('A vs D/F Students', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(top_vs_bottom['Feature'], fontsize=8)\n",
    "ax1.legend(fontsize=8)\n",
    "\n",
    "# 2. Study hours distribution by grade\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "grade_colors = {0: '#2ecc71', 1: '#3498db', 2: '#f39c12', 3: '#e74c3c'}\n",
    "for grade in [0, 1, 2, 3]:\n",
    "    subset = df[df['FinalGrade'] == grade]['StudyHours']\n",
    "    ax2.hist(subset, bins=15, alpha=0.5, label=['A', 'B', 'C', 'D/F'][grade], color=grade_colors[grade])\n",
    "ax2.set_xlabel('Study Hours')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Study Hours by Grade', fontweight='bold')\n",
    "ax2.legend(fontsize=8)\n",
    "\n",
    "# 3. Attendance vs Exam Score\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "scatter = ax3.scatter(df['Attendance'], df['ExamScore'], c=df['FinalGrade'], \n",
    "                      cmap='RdYlGn_r', alpha=0.4, s=15)\n",
    "ax3.set_xlabel('Attendance %')\n",
    "ax3.set_ylabel('Exam Score')\n",
    "ax3.set_title('Attendance vs Exam Score', fontweight='bold')\n",
    "\n",
    "# 4. Learning Style Performance\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "learning_perf = df_labeled.groupby('LearningStyleLabel')['ExamScore'].mean().sort_values(ascending=True)\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(learning_perf)))\n",
    "ax4.barh(learning_perf.index, learning_perf.values, color=colors)\n",
    "ax4.set_xlabel('Average Exam Score')\n",
    "ax4.set_title('Exam Score by Learning Style', fontweight='bold')\n",
    "\n",
    "# 5. Stress and Motivation Matrix\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "pivot = df.pivot_table(values='ExamScore', index='StressLevel', columns='Motivation', aggfunc='mean')\n",
    "sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn', ax=ax5, cbar_kws={'label': 'Exam Score'})\n",
    "ax5.set_xlabel('Motivation Level')\n",
    "ax5.set_ylabel('Stress Level')\n",
    "ax5.set_title('Exam Score: Stress vs Motivation', fontweight='bold')\n",
    "\n",
    "# 6. Age Distribution by Performance\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "for grade in [0, 3]:\n",
    "    subset = df[df['FinalGrade'] == grade]['Age']\n",
    "    label = 'A Students' if grade == 0 else 'D/F Students'\n",
    "    color = '#2ecc71' if grade == 0 else '#e74c3c'\n",
    "    ax6.hist(subset, bins=12, alpha=0.6, label=label, color=color)\n",
    "ax6.set_xlabel('Age')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_title('Age Distribution: A vs D/F', fontweight='bold')\n",
    "ax6.legend(fontsize=8)\n",
    "\n",
    "# 7. Key Statistics Summary (text)\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "ax7.axis('off')\n",
    "stats_text = f\"\"\"\n",
    "üìä KEY STATISTICS\n",
    "{'='*30}\n",
    "Total Students: {len(df):,}\n",
    "Average Exam Score: {df['ExamScore'].mean():.1f}\n",
    "A Grade Rate: {(df['FinalGrade']==0).mean()*100:.1f}%\n",
    "D/F Rate: {(df['FinalGrade']==3).mean()*100:.1f}%\n",
    "Avg Study Hours: {df['StudyHours'].mean():.1f}\n",
    "Avg Attendance: {df['Attendance'].mean():.1f}%\n",
    "\"\"\"\n",
    "ax7.text(0.1, 0.5, stats_text, fontsize=11, fontfamily='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "# 8. Top correlations\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "top_corr = correlations_sorted.head(5)\n",
    "colors = ['#2ecc71' if c < 0 else '#e74c3c' for c in top_corr.values]\n",
    "ax8.barh(top_corr.index, top_corr.values, color=colors)\n",
    "ax8.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax8.set_xlabel('Correlation with Grade (negative=better)')\n",
    "ax8.set_title('Top Success Factors', fontweight='bold')\n",
    "\n",
    "# 9. Grade distribution pie\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "grade_dist = df['FinalGrade'].value_counts().sort_index()\n",
    "colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']\n",
    "ax9.pie(grade_dist.values, labels=['A', 'B', 'C', 'D/F'], autopct='%1.1f%%',\n",
    "        colors=colors, explode=[0.05, 0, 0, 0.05])\n",
    "ax9.set_title('Grade Distribution', fontweight='bold')\n",
    "\n",
    "plt.suptitle('üìä Student Performance Dashboard', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.savefig('comprehensive_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Conclusion: Why Data Science Matters\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "In this notebook, we took **14,000+ raw records** and transformed them into **actionable insights**:\n",
    "\n",
    "1. **Identified at-risk students** before they fail\n",
    "2. **Discovered success factors** that distinguish top performers\n",
    "3. **Visualized complex relationships** that would be invisible in spreadsheets\n",
    "4. **Created predictive indicators** that can guide intervention strategies\n",
    "\n",
    "### The Business Value\n",
    "\n",
    "Without data science:\n",
    "- Manually reviewing 14,000 students would take **weeks**\n",
    "- Patterns and correlations would remain **hidden**\n",
    "- Decisions would be based on **intuition, not evidence**\n",
    "\n",
    "With data science:\n",
    "- Analysis completed in **minutes**\n",
    "- Insights are **reproducible and scalable**\n",
    "- Decisions are **data-driven and defensible**\n",
    "\n",
    "### Key Findings from Our Analysis\n",
    "\n",
    "| Finding | Implication |\n",
    "|---------|-------------|\n",
    "| Exam scores strongly predict final grades | Use early exam performance for intervention |\n",
    "| Attendance matters more than study hours | Encourage class participation |\n",
    "| High stress correlates with poor performance | Provide mental health support |\n",
    "| Assignment completion is a strong indicator | Track and follow up on missing assignments |\n",
    "| Study efficiency varies by learning style | Personalize study recommendations |\n",
    "\n",
    "---\n",
    "\n",
    "### Your Next Steps\n",
    "\n",
    "1. **Practice**: Try modifying the filters and visualizations\n",
    "2. **Explore**: What other questions can you answer with this data?\n",
    "3. **Apply**: Use these techniques on your own datasets\n",
    "4. **Learn More**: Dive into machine learning for predictive modeling\n",
    "\n",
    "---\n",
    "\n",
    "*Data science isn't just about tools and techniques‚Äîit's about asking the right questions and finding answers that matter.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary export\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ TOUR COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYou've learned:\")\n",
    "print(\"  ‚úÖ Loading and exploring data with pandas\")\n",
    "print(\"  ‚úÖ Filtering and subsetting for specific insights\")\n",
    "print(\"  ‚úÖ Creating powerful visualizations\")\n",
    "print(\"  ‚úÖ Discovering correlations and relationships\")\n",
    "print(\"  ‚úÖ Engineering new features from existing data\")\n",
    "print(\"  ‚úÖ Building predictive indicators\")\n",
    "print(\"\\nüìÅ Generated visualizations have been saved as PNG files.\")\n",
    "print(\"\\nüöÄ You're now equipped with fundamental data science skills!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
